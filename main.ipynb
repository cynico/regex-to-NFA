{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names\n",
    "* Youssef Said Ibrahim Rabie, 2, 40\n",
    "* Ahmed Fawzy, 1, 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: visual-automata===1.1.1 in ./venv/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: automata-lib in ./venv/lib/python3.11/site-packages (from visual-automata===1.1.1) (8.3.0)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (from visual-automata===1.1.1) (2.2.2)\n",
      "Requirement already satisfied: graphviz in ./venv/lib/python3.11/site-packages (from visual-automata===1.1.1) (0.20.3)\n",
      "Requirement already satisfied: colormath in ./venv/lib/python3.11/site-packages (from visual-automata===1.1.1) (3.0.0)\n",
      "Requirement already satisfied: jupyterlab in ./venv/lib/python3.11/site-packages (from visual-automata===1.1.1) (4.1.6)\n",
      "Requirement already satisfied: forbiddenfruit in ./venv/lib/python3.11/site-packages (from visual-automata===1.1.1) (0.1.4)\n",
      "Requirement already satisfied: networkx>=2.6.2 in ./venv/lib/python3.11/site-packages (from automata-lib->visual-automata===1.1.1) (3.3)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in ./venv/lib/python3.11/site-packages (from automata-lib->visual-automata===1.1.1) (2.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.11/site-packages (from automata-lib->visual-automata===1.1.1) (4.11.0)\n",
      "Requirement already satisfied: cached-method>=0.1.0 in ./venv/lib/python3.11/site-packages (from automata-lib->visual-automata===1.1.1) (0.1.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from colormath->visual-automata===1.1.1) (1.26.4)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (0.27.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (6.29.4)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (2.14.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (2.26.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (0.2.4)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (24.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (6.4)\n",
      "Requirement already satisfied: traitlets in ./venv/lib/python3.11/site-packages (from jupyterlab->visual-automata===1.1.1) (5.14.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas->visual-automata===1.1.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas->visual-automata===1.1.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas->visual-automata===1.1.1) (2024.1)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->visual-automata===1.1.1) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->visual-automata===1.1.1) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->visual-automata===1.1.1) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->visual-automata===1.1.1) (3.7)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->visual-automata===1.1.1) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->visual-automata===1.1.1) (0.14.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (8.23.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (8.6.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in ./venv/lib/python3.11/site-packages (from ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (26.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab->visual-automata===1.1.1) (2.1.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.11/site-packages (from jupyter-core->jupyterlab->visual-automata===1.1.1) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (7.16.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.20.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./venv/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (1.7.0)\n",
      "Requirement already satisfied: babel>=2.10 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (4.21.1)\n",
      "Requirement already satisfied: requests>=2.31 in ./venv/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->visual-automata===1.1.1) (1.16.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./venv/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (21.2.0)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (2.17.2)\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (0.18.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./venv/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in ./venv/lib/python3.11/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./venv/lib/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (2.2.1)\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.11/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.7.0)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.8.4)\n",
      "Requirement already satisfied: fqdn in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (2.4)\n",
      "Requirement already satisfied: uri-template in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (1.13)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.2.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./venv/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->visual-automata===1.1.1) (0.2.2)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->visual-automata===1.1.1) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./venv/lib/python3.11/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./venv/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->visual-automata===1.1.1) (2.9.0.20240316)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install visual-automata===1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing minor bugs in the package used for visualizing the NFA\n",
    "!PKG_PATH=$(pip --version | awk '{print $4}' | sed 's/pip//'); if ! grep -q \"all_transitions = dict(all_transitions).deepcopy()\" ${PKG_PATH}visual_automata/fa/nfa.py; then sed -i 's/all_transitions = all_transitions.deepcopy()/all_transitions = dict(all_transitions).deepcopy()/g' ${PKG_PATH}visual_automata/fa/nfa.py; fi\n",
    "!PKG_PATH=$(pip --version | awk '{print $4}' | sed 's/pip//'); sed -i 's/\\(for symbol, transitions in state_transitions.items():\\)/\\1\\n                transitions=set(transitions)/' ${PKG_PATH}visual_automata/fa/nfa.py\n",
    "\n",
    "# An ad-hoc solution to visualize partial DFAs\n",
    "!PKG_PATH=$(pip --version | awk '{print $4}' | sed 's/pip//'); if ! grep -q \"allow_partial: bool = False\" ${PKG_PATH}visual_automata/fa/dfa.py; then sed -i 's/\\(final_states: set = None\\)/\\1,\\n        allow_partial: bool = False/' ${PKG_PATH}visual_automata/fa/dfa.py; sed -i 's/\\(final_states=final_states,\\)/\\1\\n                allow_partial=allow_partial/' ${PKG_PATH}visual_automata/fa/dfa.py; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Set\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict\n",
    "from visual_automata.fa.nfa import VisualNFA\n",
    "from visual_automata.fa.dfa import VisualDFA\n",
    "from IPython.display import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_brackets = \"([\"\n",
    "closing_brackets = \")]\"\n",
    "bracket_pairs = {')': '(', ']': '['}\n",
    "quantifiers = ['*', '+', '?']\n",
    "epsilon = \"ε\"\n",
    "\n",
    "class OrderedSet:\n",
    "\n",
    "    def __init__(self, elements=None):\n",
    "        self.dict = OrderedDict()\n",
    "        if elements is not None:\n",
    "            for element in elements:\n",
    "                self.add(element)\n",
    "\n",
    "    def add(self, element):\n",
    "        self.dict[element] = None\n",
    "\n",
    "    def update(self, elements):\n",
    "        for element in elements:\n",
    "            self.add(element)\n",
    "\n",
    "    def discard(self, element):\n",
    "        self.dict.pop(element, None)\n",
    "\n",
    "    def remove(self, element):\n",
    "        try:\n",
    "            del self.dict[element]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Element '{element}' not found in OrderedSet\")\n",
    "\n",
    "    def intersection(self, other):\n",
    "        common_elements = (element for element in self if element in other)\n",
    "        return OrderedSet(common_elements)\n",
    "\n",
    "    def __contains__(self, element):\n",
    "        return element in self.dict\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dict)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"OrderedSet({list(self.dict.keys())})\"\n",
    "\n",
    "    def __set__(self):\n",
    "        return set(self.dict.keys())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return list(self.dict.keys())[index]\n",
    "        except IndexError:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "class ListOfSubExpressionsType(Enum):\n",
    "    CONCATENATED = 1\n",
    "    ORED = 2\n",
    "\n",
    "@dataclass\n",
    "class SubExpression:\n",
    "    quantifier: str\n",
    "    expression: str # This is the string expression if this SubExpression node is a leaf node.\n",
    "    subtype: ListOfSubExpressionsType # This defines the relationship between the list of ListOfSubExpressions\n",
    "    subexpression: List['ListOfSubExpressions']\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ListOfSubExpressions:\n",
    "    ltype: ListOfSubExpressionsType # This defines the relationship between the list of SubExpressions\n",
    "    llist: List['SubExpression']\n",
    "\n",
    "class AutomatonType(Enum):\n",
    "    NFA = 1\n",
    "    DFA = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the regex expression is valid or not\n",
    "# Rules applied:\n",
    "# 1. Unopened brackets/parentheses\n",
    "# 2. No two consecutive quantifiers, unless the previous one is escaped, in which case it is treated literally. \n",
    "def check_if_valid(expression: str) -> bool:\n",
    "\n",
    "    stack = []\n",
    "    \n",
    "    # Forbidden symbols at the beginning of the string\n",
    "    if expression[0] in quantifiers: return False\n",
    "\n",
    "    # Looping over the string\n",
    "    for i in range(len(expression)):\n",
    "        \n",
    "        # Checking brackets are opened and closed properly\n",
    "        if expression[i] in opening_brackets:\n",
    "            stack.append(expression[i])\n",
    "        elif expression[i] in closing_brackets:\n",
    "            if not stack or stack.pop() != bracket_pairs[expression[i]]: return False\n",
    "        \n",
    "        # Checking that no invalid sequence of two consecutive quantifiers occur\n",
    "        elif expression[i] in quantifiers:\n",
    "            previous_quantifier = expression[i-1] in quantifiers\n",
    "            if previous_quantifier:                \n",
    "                if i-2 >= 0:\n",
    "                    if expression[i-2] == '\\\\': continue \n",
    "                \n",
    "                return False\n",
    "\n",
    "    return not stack\n",
    "\n",
    "# This function checks if a string ends with a certain character, with optional characters to ignore/discard when checking\n",
    "def find_if_it_ends_with(string: str, char_to_find: str, chars_to_ignore: List[str], chars_not_to_ignore: List[str]) -> bool:\n",
    "    \n",
    "    for i in range(len(string)-1, -1, -1):\n",
    "        \n",
    "        # Default values for the lists in case one is not supplied\n",
    "        if chars_to_ignore is None: chars_to_ignore = []\n",
    "        if chars_not_to_ignore is None: chars_not_to_ignore = string \n",
    "\n",
    "        if (string[i] in chars_to_ignore) or (string[i] not in chars_not_to_ignore): continue\n",
    "        elif string[i] == char_to_find: return True\n",
    "        else: return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Check if a string is a parenthetical string, with optional quantifiers added to the end of it.\n",
    "def check_if_parenthetical(string: str) -> bool:\n",
    "\n",
    "    if string[0] != '(': return False\n",
    "    return find_if_it_ends_with(string=string, char_to_find=')', chars_to_ignore=quantifiers, chars_not_to_ignore=None)\n",
    "\n",
    "# Check if a string is a bracketed string, with optional quantifiers added to the end of it.\n",
    "def check_if_bracketed(string: str) -> bool:\n",
    "\n",
    "    if string[0] != '[': return False\n",
    "    return find_if_it_ends_with(string=string, char_to_find=']', chars_to_ignore=quantifiers, chars_not_to_ignore=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting string expression into string subexpressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the string expression into string subexpressions valid to be subject to Thompson's Rule\n",
    "def split_string_expression(expression: str) -> List[str]:\n",
    "    \n",
    "    sub_string_expressions = []\n",
    "    brackets_stack = []\n",
    "    current_sub_string_expression = ''\n",
    "\n",
    "    for i in range(len(expression)):\n",
    "\n",
    "        # Opening brackets MAY start a new sub-expression \n",
    "        if expression[i] in opening_brackets:\n",
    "            \n",
    "            # If we are not inside another set of brackets, then this is a new sub-expression\n",
    "            if not brackets_stack:\n",
    "                if current_sub_string_expression: sub_string_expressions.append(current_sub_string_expression)\n",
    "                current_sub_string_expression = expression[i]\n",
    "            \n",
    "            # If we are, then it is not.\n",
    "            else: current_sub_current_sub_string_expressionexpression += expression[i]\n",
    "\n",
    "            brackets_stack.append(expression[i])\n",
    "        \n",
    "        # Literals start a new sub-expression if we are not inside a bracket/parenthesis\n",
    "        elif (expression[i] not in quantifiers) and (expression[i] not in closing_brackets):\n",
    "            \n",
    "            if not brackets_stack:\n",
    "                if current_sub_string_expression: sub_string_expressions.append(current_sub_string_expression)\n",
    "                current_sub_string_expression = expression[i]\n",
    "            else:\n",
    "                current_sub_string_expression += expression[i]\n",
    "        \n",
    "        # Quantifiers and closing brackets do not start a new sub-expression\n",
    "        else :\n",
    "            current_sub_string_expression += expression[i]\n",
    "            if expression[i] in closing_brackets: brackets_stack.pop()\n",
    "\n",
    "\n",
    "    if current_sub_string_expression: sub_string_expressions.append(current_sub_string_expression)\n",
    "\n",
    "    return sub_string_expressions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the string expression into a recursive SubExpression dataclass (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns tuple of (string of subexpression, quantifier)\n",
    "def split_quantifier(sub_string_expression: str, is_bracketed: bool) -> Tuple[str, str]:\n",
    "    \n",
    "    quant_start_idx = len(sub_string_expression)\n",
    "\n",
    "    for i in range(len(sub_string_expression)-1, -1, -1):\n",
    "        if sub_string_expression[i] in quantifiers: quant_start_idx = i \n",
    "        else: break\n",
    "\n",
    "    q = None if quant_start_idx == len(sub_string_expression) else sub_string_expression[quant_start_idx:]\n",
    "    # Strip brackets and quantifiers\n",
    "    s = sub_string_expression[1:quant_start_idx-1] if is_bracketed else sub_string_expression[0:quant_start_idx]\n",
    "\n",
    "    return (s, q)\n",
    "\n",
    "# Converts the string expression into a recursive SubExpression dataclass\n",
    "def convert_to_subexpression(expression: str) -> SubExpression:\n",
    "\n",
    "    def convert(subexpression_string: str) -> SubExpression:\n",
    "\n",
    "        if check_if_parenthetical(subexpression_string):\n",
    "            \n",
    "            s, q = split_quantifier(sub_string_expression=subexpression_string, is_bracketed=True)\n",
    "\n",
    "            substrings = split_string_expression(s)\n",
    "            list_of_list_of_subexpressions = [list()]\n",
    "            ored = False\n",
    "        \n",
    "            for substring in substrings:\n",
    "                if substring == '|': \n",
    "                    ored = True\n",
    "                    list_of_list_of_subexpressions.append(list())\n",
    "                else:\n",
    "                    list_of_list_of_subexpressions[len(list_of_list_of_subexpressions)-1].append(convert(substring))\n",
    "\n",
    "            l = []\n",
    "            for list_of_subexpressions in list_of_list_of_subexpressions:\n",
    "                l.append(ListOfSubExpressions(ltype=ListOfSubExpressionsType.CONCATENATED, llist=list_of_subexpressions))\n",
    "\n",
    "            return SubExpression(quantifier=q, expression=None, \n",
    "                                subexpression=l, subtype=ListOfSubExpressionsType(ored+1))\n",
    "\n",
    "        # Base case\n",
    "        else:\n",
    "            s, q = split_quantifier(sub_string_expression=subexpression_string, is_bracketed=False) \n",
    "            if check_if_bracketed(s): s = s[1:len(s)-1]\n",
    "            return SubExpression(quantifier=q, expression=s, subexpression=None, subtype=ListOfSubExpressionsType.CONCATENATED)\n",
    "\n",
    "    \n",
    "    if not check_if_valid(expression): return None\n",
    "\n",
    "    substrings = split_string_expression(expression)\n",
    "    subexpressions = []\n",
    "\n",
    "    for substring in substrings: subexpressions.append(convert(substring))\n",
    "    l = ListOfSubExpressions(ltype=ListOfSubExpressionsType.CONCATENATED, llist=subexpressions)\n",
    "    \n",
    "    # Root SubExpression node, with a quantifier of None, and subexpression = the list above\n",
    "    return SubExpression(quantifier=None, expression=None, subexpression=[l], subtype=ListOfSubExpressionsType.CONCATENATED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the SubExpression dataclass tree to a json/dict NFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_states(fa: OrderedDict) -> OrderedDict:\n",
    "\n",
    "    # This function takes a FA, and renames its states with ascending numbers according to the order of states\n",
    "    renamed_symbols = {}\n",
    "    i = 0\n",
    "\n",
    "    for key in fa.keys():\n",
    "        if key == \"startingState\": continue\n",
    "        renamed_symbols[key] = f\"X{i}\"\n",
    "        i += 1 \n",
    "    \n",
    "    renamed_fa = str(fa)\n",
    "    for old_symbol, new_symbol in renamed_symbols.items(): renamed_fa = renamed_fa.replace(f\"'{old_symbol}'\", f\"'{new_symbol}'\")\n",
    "    renamed_fa = renamed_fa.replace(\"X\", \"S\")\n",
    "\n",
    "    return OrderedDict(eval(renamed_fa))\n",
    "\n",
    "def add_transition(nfa: OrderedDict, source_state: str, input_symbol: str, dest_states: List[str]):\n",
    "\n",
    "    # Adds a transition from the source state in the NFA on input_symbol to the destination states in dest_states\n",
    "    if input_symbol in nfa[source_state]: nfa[source_state][input_symbol] += dest_states\n",
    "    else: nfa[source_state][input_symbol] = dest_states\n",
    "\n",
    "# \n",
    "def combine_subnfas(list_of_subnfas: List[OrderedDict], type: ListOfSubExpressionsType, counter: int) -> (OrderedDict, int):\n",
    "\n",
    "    combined_nfa = OrderedDict()\n",
    "    if type == ListOfSubExpressionsType.CONCATENATED:\n",
    "        \n",
    "        for i in range(len(list_of_subnfas)):\n",
    "            list_of_keys = list(list_of_subnfas[i].keys())\n",
    "            \n",
    "            # Delete the startingState key in all SubExpressions except the first one\n",
    "            if i != 0: del list_of_subnfas[i][\"startingState\"]\n",
    "\n",
    "            # If this is not the last one, make its final state not a terminating state,\n",
    "            # and add an edge from it to the starting state of the next SubExpression on ε input \n",
    "            if i != len(list_of_subnfas) - 1:\n",
    "                \n",
    "                terminating_states = []\n",
    "                for state in list_of_subnfas[i]:\n",
    "                    if state == \"startingState\": continue\n",
    "                    if list_of_subnfas[i][state][\"isTerminatingState\"]:\n",
    "                        list_of_subnfas[i][state][\"isTerminatingState\"] = False\n",
    "                        terminating_states.append(state) \n",
    "                \n",
    "                for terminating_state in terminating_states: \n",
    "                    add_transition(nfa=list_of_subnfas[i], source_state=terminating_state, input_symbol=epsilon, dest_states=[list_of_subnfas[i+1][\"startingState\"]])\n",
    "\n",
    "            combined_nfa.update(list_of_subnfas[i])\n",
    "\n",
    "    else:\n",
    "\n",
    "        starting_state = f\"S{counter+1}\"\n",
    "        combined_nfa[\"startingState\"] = starting_state\n",
    "        combined_nfa[starting_state] = {\n",
    "            \"isTerminatingState\": False\n",
    "        }\n",
    "        counter += 1\n",
    "        \n",
    "        terminating_state = f\"S{counter+1}\"\n",
    "        combined_nfa[terminating_state] = {\n",
    "            \"isTerminatingState\": True\n",
    "        }\n",
    "        counter += 1\n",
    "\n",
    "        prev_starting_states = []\n",
    "        for i in range(len(list_of_subnfas)):\n",
    "            \n",
    "            list_of_keys = list(list_of_subnfas[i].keys())\n",
    "            \n",
    "            # Get the terminating states, and change them to be non-terminating\n",
    "            for key in list_of_keys:\n",
    "                if key == \"startingState\": continue\n",
    "                \n",
    "                if list_of_subnfas[i][key][\"isTerminatingState\"]:\n",
    "                    list_of_subnfas[i][key][\"isTerminatingState\"] = False\n",
    "                    add_transition(nfa=list_of_subnfas[i], source_state=key, input_symbol=epsilon, dest_states=[terminating_state])\n",
    "\n",
    "            # Get the starting states and append them to the list\n",
    "            prev_starting_states.append(list_of_subnfas[i][\"startingState\"])\n",
    "\n",
    "            del list_of_subnfas[i][\"startingState\"]\n",
    "\n",
    "            combined_nfa.update(list_of_subnfas[i])\n",
    "\n",
    "        add_transition(nfa=combined_nfa, source_state=starting_state, input_symbol=epsilon, dest_states=prev_starting_states)\n",
    "\n",
    "    return (combined_nfa, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_quantifier_logic_thompson(sub_nfa: OrderedDict, counter: int, quantifier: str) -> (OrderedDict, int):\n",
    "\n",
    "    sub_nfa_copy = sub_nfa.deepcopy()\n",
    "    quantified_nfa = OrderedDict()\n",
    "\n",
    "    if quantifier in [\"*\", \"+\"]:\n",
    "        \n",
    "        # Inserting the new starting state\n",
    "        starting_state = f\"S{counter+1}\"\n",
    "        quantified_nfa[\"startingState\"] = starting_state\n",
    "        quantified_nfa[starting_state] = {\n",
    "            \"isTerminatingState\": False\n",
    "        }\n",
    "        counter += 1\n",
    "        \n",
    "        terminating_state = f\"S{counter+1}\"\n",
    "        counter += 1\n",
    "\n",
    "        # Deleting the previous startingState key\n",
    "        # Inserting the appropriate edges from the new starting state on ε input\n",
    "        prev_starting_state = sub_nfa_copy[\"startingState\"]\n",
    "        del sub_nfa_copy [\"startingState\"]\n",
    "\n",
    "        add_transition(nfa=quantified_nfa, source_state=starting_state, input_symbol=epsilon, dest_states=[prev_starting_state])\n",
    "        if quantifier == \"*\":\n",
    "            add_transition(nfa=quantified_nfa, source_state=starting_state, input_symbol=epsilon, dest_states=[terminating_state]) \n",
    "\n",
    "        # The previous terminating states are no longer terminating\n",
    "        # Inserting the appropriate edges from the previous terminating states on ε input\n",
    "        for key in sub_nfa_copy.keys():\n",
    "            if key == \"startingState\": continue\n",
    "            if sub_nfa_copy[key][\"isTerminatingState\"]:\n",
    "                add_transition(nfa=sub_nfa_copy, source_state=key, input_symbol=epsilon, dest_states=[starting_state, terminating_state])\n",
    "                sub_nfa_copy[key][\"isTerminatingState\"] = False\n",
    "\n",
    "        # Inserting the updated states of d\n",
    "        quantified_nfa.update(sub_nfa_copy)\n",
    "        \n",
    "        # Inserting the terminating state (this has to be done here to preserve\n",
    "        # the order of key insertion)\n",
    "        quantified_nfa[terminating_state] = {\n",
    "            \"isTerminatingState\": True\n",
    "        }\n",
    "    elif quantifier == \"?\":\n",
    "        \n",
    "        terminating_states = []\n",
    "        for state in sub_nfa_copy.keys():\n",
    "            if state == \"startingState\": continue\n",
    "            if sub_nfa_copy[state][\"isTerminatingState\"]: terminating_states.append(state)\n",
    "\n",
    "        starting_state = sub_nfa_copy[\"startingState\"]\n",
    "        quantified_nfa.update(sub_nfa_copy)\n",
    "        add_transition(nfa=quantified_nfa, source_state=starting_state, input_symbol=epsilon, dest_states=terminating_states)\n",
    "            \n",
    "    else:\n",
    "        quantified_nfa.update(sub_nfa_copy)\n",
    "    \n",
    "    return (quantified_nfa, counter)\n",
    "\n",
    "\n",
    "def convert_to_nfa(subexpression: SubExpression, counter: int) -> (OrderedDict, int):\n",
    "        \n",
    "    # Base case\n",
    "    if subexpression.subexpression is None:\n",
    "        \n",
    "        sub_nfa = OrderedDict({\n",
    "            \"startingState\": f\"S{counter+1}\",\n",
    "            f\"S{counter+1}\": {\n",
    "                \"isTerminatingState\": False,\n",
    "                f\"{subexpression.expression}\": [f\"S{counter+2}\"]\n",
    "            },\n",
    "            f\"S{counter+2}\": {\n",
    "                \"isTerminatingState\": True\n",
    "            }\n",
    "        })\n",
    "        counter += 2\n",
    "        nfa, counter = handle_quantifier_logic_thompson(sub_nfa=sub_nfa, counter=counter, quantifier=subexpression.quantifier)\n",
    "    else:\n",
    "    \n",
    "        list_of_combined_subnfas = []\n",
    "\n",
    "        for l in subexpression.subexpression:\n",
    "\n",
    "            list_of_subnfas = []\n",
    "            for s in l.llist:\n",
    "                d, counter = convert_to_nfa(s, counter)\n",
    "                list_of_subnfas.append(d)\n",
    "\n",
    "            combined_subnfa, counter = combine_subnfas(list_of_subnfas, l.ltype, counter)\n",
    "            list_of_combined_subnfas.append(combined_subnfa)\n",
    "        \n",
    "        sub_nfa, counter = combine_subnfas(list_of_combined_subnfas, subexpression.subtype, counter)\n",
    "        nfa, counter = handle_quantifier_logic_thompson(sub_nfa=sub_nfa, counter=counter, quantifier=subexpression.quantifier)\n",
    "\n",
    "    return (nfa, counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting string regex expression to an NFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(expression: str) -> OrderedDict:\n",
    "    subexpression = convert_to_subexpression(expression)\n",
    "    nfa = rename_states(convert_to_nfa(subexpression, -1)[0])\n",
    "    return nfa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    fa: OrderedDict, \n",
    "    type: AutomatonType,\n",
    "    allow_partial: bool = False\n",
    "):\n",
    "\n",
    "    copied_fa = fa.deepcopy()\n",
    "\n",
    "    states = set(copied_fa.keys())\n",
    "    states.remove(\"startingState\")\n",
    "\n",
    "    terminating_states = get_terminating_states(fa=fa)\n",
    "    input_symbols = get_input_symbols(fa=fa)\n",
    "\n",
    "    for key in copied_fa.keys():\n",
    "        if key == \"startingState\": continue\n",
    "        del copied_fa[key][\"isTerminatingState\"]\n",
    "\n",
    "        for input_symbol in copied_fa[key].keys():\n",
    "\n",
    "            if not isinstance(copied_fa[key][input_symbol], list):\n",
    "                copied_fa[key][input_symbol] = copied_fa[key][input_symbol]\n",
    "            else:\n",
    "                copied_fa[key][input_symbol] = set(copied_fa[key][input_symbol])\n",
    "    \n",
    "    del copied_fa[\"startingState\"]\n",
    "\n",
    "    if type == AutomatonType.NFA:\n",
    "        visual_fa = VisualNFA(\n",
    "            states=states,\n",
    "            input_symbols=set(input_symbols),\n",
    "            transitions=dict(copied_fa),\n",
    "            initial_state=fa[\"startingState\"],\n",
    "            final_states=set(terminating_states),\n",
    "        )\n",
    "    else:\n",
    "        visual_fa = VisualDFA(\n",
    "            states=states,\n",
    "            input_symbols=set(input_symbols),\n",
    "            transitions=dict(copied_fa),\n",
    "            initial_state=fa[\"startingState\"],\n",
    "            final_states=set(terminating_states),\n",
    "            allow_partial=allow_partial\n",
    "        )\n",
    "\n",
    "    # Forcing the diagram to show by wrapping it in IPython.display.display\n",
    "    display(visual_fa.show_diagram())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Construction Algorithm, and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_closure(nfa: OrderedDict, states: Set) -> Set:\n",
    "\n",
    "    closure, queue, processed = set(), set(), set()\n",
    "\n",
    "    for state in states: queue.add(state)\n",
    "\n",
    "    while queue:\n",
    "        \n",
    "        s = queue.pop()\n",
    "        if s in processed: continue\n",
    "        closure.add(s)\n",
    "    \n",
    "        try:\n",
    "            epsilon_transitions = nfa[s][epsilon]\n",
    "            closure.update(epsilon_transitions)\n",
    "            queue.update(epsilon_transitions)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        processed.add(s)\n",
    "\n",
    "    return closure\n",
    "\n",
    "def get_terminating_states(fa: OrderedDict) -> OrderedSet:\n",
    "\n",
    "    terminating_states = []\n",
    "    for state in fa.keys():\n",
    "        if state == \"startingState\": continue\n",
    "        if fa[state][\"isTerminatingState\"]: terminating_states.append(state)\n",
    "\n",
    "    return OrderedSet(terminating_states)\n",
    "\n",
    "def get_input_symbols(fa: OrderedDict) -> OrderedSet:\n",
    "\n",
    "    input_symbols = OrderedSet()\n",
    "    for s in fa.keys():\n",
    "        if s == \"startingState\": continue\n",
    "        input_symbols.update(list(fa[s].keys()))\n",
    "\n",
    "    input_symbols.remove(\"isTerminatingState\")\n",
    "\n",
    "    return input_symbols\n",
    "\n",
    "def check_if_state_exists(fa: OrderedDict, state: Tuple) -> bool:\n",
    "\n",
    "    state_as_set = set(state)\n",
    "    for key in fa.keys():\n",
    "        if state_as_set == set(key): return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Return the set from a list of sets that intersects with the given set elementS\n",
    "# The set elementS can optionally contain 1 element, in which case we're simply\n",
    "# checking for membership of an item in the set\n",
    "\n",
    "# If there are multiple sets that intersect with the given set, we simply return\n",
    "# the first. Our use case, either way, only happens to be that this given set will\n",
    "# intersect only ever with 1 set from the list\n",
    "def get_set_of_a_member(sets: List[Set], elementS: Set) -> Set:\n",
    "    for s in sets:\n",
    "        if s.intersection(elementS): return s\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_construction(nfa: OrderedDict) -> OrderedDict:\n",
    "\n",
    "    starting_state = epsilon_closure(nfa=nfa, states=set([nfa[\"startingState\"]]))\n",
    "    terminating_states = get_terminating_states(fa=nfa)\n",
    "\n",
    "    input_symbols = get_input_symbols(fa=nfa)\n",
    "    input_symbols.discard(epsilon)\n",
    "\n",
    "    dfa = OrderedDict({\n",
    "        \"startingState\": tuple(starting_state)\n",
    "    })\n",
    "\n",
    "    # Set of states to process\n",
    "    # Each DFA state is a set of previous NFA states\n",
    "    queue = set()\n",
    "    queue.add(tuple(starting_state))\n",
    "\n",
    "    while queue:\n",
    "        \n",
    "        dfa_state = queue.pop()\n",
    "\n",
    "        if check_if_state_exists(fa=dfa, state=dfa_state): continue\n",
    "        else:\n",
    "            dfa[dfa_state] = {\n",
    "                \"isTerminatingState\": bool(set(dfa_state).intersection(terminating_states))\n",
    "            }\n",
    "\n",
    "        for input_symbol in input_symbols:\n",
    "            \n",
    "            target_dfa_state = set()\n",
    "\n",
    "            for nfa_state in dfa_state:\n",
    "                try:\n",
    "                    s = nfa[nfa_state][input_symbol]\n",
    "                    target_dfa_state.update(s)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        \n",
    "            target_dfa_state.update(epsilon_closure(nfa=nfa, states=target_dfa_state))\n",
    "            target_dfa_state = tuple(target_dfa_state)\n",
    "            queue.add(target_dfa_state)\n",
    "            dfa[dfa_state][input_symbol] = target_dfa_state\n",
    "    \n",
    "    stringified_dfa = dfa.deepcopy()\n",
    "\n",
    "    for state in dfa.keys():\n",
    "        \n",
    "        if state == \"startingState\":\n",
    "            stringified_dfa[\"startingState\"] = ','.join(sorted(list(dfa[\"startingState\"])))\n",
    "            continue\n",
    "\n",
    "        state_string = ','.join(sorted([s for s in state]))\n",
    "        #if state_string == \"\": state_string = \"phi\"\n",
    "        stringified_dfa[state_string] = dfa[state]\n",
    "\n",
    "        del stringified_dfa[state]\n",
    "\n",
    "        for transition_input, transition_state in dfa[state].items():\n",
    "            if transition_input == \"isTerminatingState\": continue\n",
    "\n",
    "            destination_state = ','.join(sorted([s for s in transition_state]))\n",
    "            #if destination_state == \"\": destination_state = \"phi\" \n",
    "            stringified_dfa[state_string][transition_input] = destination_state \n",
    "\n",
    "\n",
    "    return stringified_dfa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFA Minimization Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_dfa(dfa: OrderedDict, eliminate_dead_states: bool = False) -> OrderedDict:\n",
    "\n",
    "    minimized_dfa = dfa.deepcopy()\n",
    "    input_symbols = get_input_symbols(fa=minimized_dfa)\n",
    "\n",
    "    # First, elimintaing all inaccessible states\n",
    "    # Inaccessible states: All those states which can never be reached from the initial state are called as inaccessible states.\n",
    "    accessible_states_queue = set([destination_state for destination_state in dfa[dfa[\"startingState\"]].values()] + [dfa[\"startingState\"]])\n",
    "    accessible_states_queue.remove(dfa[dfa[\"startingState\"]][\"isTerminatingState\"])\n",
    "    accessible_states = set()\n",
    "\n",
    "    while accessible_states_queue:\n",
    "        state  = accessible_states_queue.pop()\n",
    "        for destination_state in dfa[state].values():\n",
    "            if not isinstance(destination_state, str): continue\n",
    "            if state not in accessible_states: accessible_states_queue.add(destination_state)\n",
    "        accessible_states.add(state)\n",
    "\n",
    "    # Remove inaccessible states\n",
    "    inaccessible_states = set(dfa.keys())\n",
    "    inaccessible_states.remove(\"startingState\")\n",
    "    inaccessible_states.difference_update(accessible_states) \n",
    "    for inaccessible_state in inaccessible_states: del minimized_dfa[inaccessible_state]\n",
    "\n",
    "    if eliminate_dead_states:\n",
    "        # Secondly, eliminating all dead states: all those non-final states \n",
    "        # which transit to itself for all input symbols in ∑\n",
    "        dead_states = set()\n",
    "        for state in minimized_dfa.keys():\n",
    "            if state == \"startingState\": continue\n",
    "            if len(set(minimized_dfa[state].values())) == 2 and not minimized_dfa[state][\"isTerminatingState\"] and minimized_dfa[state][input_symbols[0]] == state:\n",
    "                dead_states.add(state)\n",
    "\n",
    "        for dead_state in dead_states: del minimized_dfa[dead_state]\n",
    "\n",
    "        for state in minimized_dfa.keys():\n",
    "            if state == \"startingState\": continue\n",
    "            for input_symbol in input_symbols:\n",
    "                if minimized_dfa[state][input_symbol] in dead_states:del minimized_dfa[state][input_symbol]\n",
    "\n",
    "    # Then grouping and combining states\n",
    "    terminating_states = get_terminating_states(fa=minimized_dfa)\n",
    "    other_states = set(minimized_dfa.keys())\n",
    "    other_states.difference_update(terminating_states)\n",
    "    other_states.remove(\"startingState\")\n",
    "    \n",
    "    groups = [other_states, terminating_states]\n",
    "    queue = set([frozenset(other_states), frozenset(terminating_states)])\n",
    "\n",
    "    while queue:\n",
    "\n",
    "        group = queue.pop()\n",
    "\n",
    "        if len(group) == 1: continue\n",
    "\n",
    "        d = {state : dict() for state in group}\n",
    "        for state in group:\n",
    "            for input_symbol in input_symbols:\n",
    "                d[state][input_symbol] = list(get_set_of_a_member(sets=groups, elementS=set([minimized_dfa[state][input_symbol]])))\n",
    "        \n",
    "        # reversed_d: keys are possible combinations of transitions, and the values are\n",
    "        # the list of states that agree on that combination => those states stay within the\n",
    "        # same group for the next iteration\n",
    "        reversed_d = defaultdict(list)\n",
    "        for state, transitions in d.items():\n",
    "            reversed_d[json.dumps(transitions, sort_keys=True)].append(state)\n",
    "\n",
    "        new_groups = groups.copy()\n",
    "        for possible_new_group in reversed_d.values():\n",
    "\n",
    "            p = set(possible_new_group)\n",
    "            if p not in groups:\n",
    "                \n",
    "                # Get the old group (from the previous iteration) containing the states in p\n",
    "                old_group = get_set_of_a_member(sets=groups, elementS=p)\n",
    "                if old_group is not None:\n",
    "                    if old_group in new_groups: new_groups.remove(old_group)\n",
    "                    queue.discard(old_group)\n",
    "                    new_groups.append(p)\n",
    "                    queue.add(frozenset(p))\n",
    "\n",
    "        groups = new_groups\n",
    "\n",
    "    # If the number of groups is equal to the number of states\n",
    "    # -1 because dfa has a key that is not a state: \"startingState\" key\n",
    "    if len(groups) == len(dfa) - 1: return minimized_dfa\n",
    "\n",
    "    for group in groups:\n",
    "        \n",
    "        if len(group) == 1: continue\n",
    "\n",
    "        # Choosing the state to keep according to the following priorities:\n",
    "        # 1. Start state\n",
    "        # 2. Accepting state\n",
    "        # 3. Transition from that state to another outsided on any input\n",
    "        state_to_keep = None\n",
    "        is_chosen_terminating_state = False\n",
    "        for state in group:\n",
    "            if state == dfa[\"startingState\"]:\n",
    "                state_to_keep = state\n",
    "                break\n",
    "            \n",
    "            if (not is_chosen_terminating_state) and (state in terminating_states):\n",
    "                state_to_keep = state\n",
    "                is_chosen_terminating_state = True\n",
    "                continue\n",
    "            \n",
    "            if state_to_keep is None:\n",
    "                for input_symbol in input_symbols:\n",
    "                    if dfa[state][input_symbol] not in group:\n",
    "                        state_to_keep = state \n",
    "                        break\n",
    "        \n",
    "        group.difference_update(set([state_to_keep]))\n",
    "\n",
    "        for discarded_state in group:\n",
    "            \n",
    "            del minimized_dfa[discarded_state]\n",
    "\n",
    "            # Add an outgoing transition to ourselves if needed\n",
    "            for input_symbol, destination_state in dfa[discarded_state].items():\n",
    "                if destination_state == discarded_state:\n",
    "                    minimized_dfa[state_to_keep][input_symbol] = state_to_keep\n",
    "\n",
    "            # Updating ingoing transitions\n",
    "            for state in dfa.keys():\n",
    "\n",
    "                if state == \"startingState\": continue\n",
    "\n",
    "                # If it is a discarded state, then there is no need to check the edges outgoing from\n",
    "                # it to other discarded states\n",
    "                if state not in minimized_dfa: continue\n",
    "\n",
    "                for input_symbol, destination_state in dfa[state].items():\n",
    "                    if destination_state == discarded_state:\n",
    "                        minimized_dfa[state][input_symbol] = state_to_keep\n",
    "\n",
    "    return minimized_dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFA and DFA test cases for the subset construction and DFA Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NFAs\n",
    "example_1 = OrderedDict({\n",
    "    \"startingState\": \"A\",\n",
    "    \"A\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        epsilon: [\"B\", \"H\"],\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        epsilon: [\"C\", \"D\"],\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"1\": [\"E\"]\n",
    "    },\n",
    "    \"D\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": [\"F\"]\n",
    "    },\n",
    "    \"E\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        epsilon: [\"G\"]\n",
    "    },\n",
    "    \"F\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        epsilon: [\"G\"]\n",
    "    },\n",
    "    \"G\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        epsilon: [\"A\", \"H\"]\n",
    "    },\n",
    "    \"H\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        epsilon: [\"I\"]\n",
    "    },\n",
    "    \"I\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"1\": [\"J\"]\n",
    "    },\n",
    "    \"J\": {\n",
    "        \"isTerminatingState\": True\n",
    "    }\n",
    "})\n",
    "\n",
    "example_2 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": ['q0'],\n",
    "        \"b\": [\"q0\", \"q1\"]\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"b\": [\"q2\"]\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": True\n",
    "    }\n",
    "})\n",
    "\n",
    "example_3 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": [\"q0\"],\n",
    "        \"1\": [\"q1\", \"q2\"]\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": [\"q1\", \"q2\"],\n",
    "        \"1\": [\"q2\"]\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"0\": [\"q0\", \"q1\"],\n",
    "        \"1\": [\"q1\"]\n",
    "    }\n",
    "})\n",
    "\n",
    "example_4 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": [\"q1\", \"q2\"],\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": False\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"a\": [\"q1\", \"q2\"],\n",
    "        \"b\": [\"q2\"]\n",
    "    }\n",
    "})\n",
    "\n",
    "example_5 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": [\"q0\"],\n",
    "        \"1\": [\"q0\", \"q1\"]\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": [\"q2\"],\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": True,\n",
    "    }\n",
    "})\n",
    "\n",
    "####### DFAs\n",
    "\n",
    "# example from the slides\n",
    "example_6 = OrderedDict({\n",
    "    \"startingState\": \"A\",\n",
    "    \"A\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"B\",\n",
    "        \"b\": \"C\"\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"B\",\n",
    "        \"b\": \"D\"\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"B\",\n",
    "        \"b\": \"C\"\n",
    "    },\n",
    "    \"D\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"B\",\n",
    "        \"b\": \"E\"\n",
    "    },\n",
    "    \"E\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"a\": \"B\",\n",
    "        \"b\": \"C\" \n",
    "    }\n",
    "})\n",
    "\n",
    "example_7 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q2\"\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q3\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q2\"\n",
    "    },\n",
    "    \"q3\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q4\"\n",
    "    },\n",
    "    \"q4\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q2\"\n",
    "    }\n",
    "})\n",
    "\n",
    "example_8 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q0\"\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"a\": \"q2\",\n",
    "        \"b\": \"q1\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q2\"\n",
    "    },\n",
    "    \"q3\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"a\": \"q1\",\n",
    "        \"b\": \"q2\"\n",
    "    }\n",
    "})\n",
    "\n",
    "example_9 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q1\",\n",
    "        \"1\": \"q2\"\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q2\",\n",
    "        \"1\": \"q3\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q2\",\n",
    "        \"1\": \"q4\"\n",
    "    },\n",
    "    \"q3\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"0\": \"q3\",\n",
    "        \"1\": \"q3\"\n",
    "    },\n",
    "    \"q4\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"0\": \"q4\",\n",
    "        \"1\": \"q4\"\n",
    "    },\n",
    "    \"q5\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q5\",\n",
    "        \"1\": \"q4\"\n",
    "    }\n",
    "})\n",
    "example_10 = OrderedDict({\n",
    "    \"startingState\": \"q0\",\n",
    "    \"q0\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q3\",\n",
    "        \"1\": \"q1\"\n",
    "    },\n",
    "    \"q1\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"0\": \"q2\",\n",
    "        \"1\": \"q5\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"0\": \"q2\",\n",
    "        \"1\": \"q5\"\n",
    "    },\n",
    "    \"q3\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q0\",\n",
    "        \"1\": \"q4\"\n",
    "    },\n",
    "    \"q4\": {\n",
    "        \"isTerminatingState\": True,\n",
    "        \"0\": \"q2\",\n",
    "        \"1\": \"q5\"\n",
    "    },\n",
    "    \"q5\": {\n",
    "        \"isTerminatingState\": False,\n",
    "        \"0\": \"q5\",\n",
    "        \"1\": \"q5\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main entrypoint code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 10.0.1 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"576pt\" height=\"80pt\"\n viewBox=\"0.00 0.00 576.00 80.17\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.383132 0.383132) rotate(0) translate(4 205.25)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-205.25 1499.4,-205.25 1499.4,4 -4,4\"/>\n<!-- Initial -->\n<g id=\"node1\" class=\"node\">\n<title>Initial</title>\n<ellipse fill=\"black\" stroke=\"black\" cx=\"1.8\" cy=\"-103\" rx=\"1.8\" ry=\"1.8\"/>\n</g>\n<!-- S0 -->\n<g id=\"node2\" class=\"node\">\n<title>S0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"64.98\" cy=\"-103\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"64.98\" y=\"-98.33\" font-family=\"Times,serif\" font-size=\"14.00\">S0</text>\n</g>\n<!-- Initial&#45;&gt;S0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>Initial&#45;&gt;S0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3.86,-103C7.28,-103 18.48,-103 30.31,-103\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.21,-105.98 38.71,-103 30.21,-100.03 30.21,-105.98\"/>\n</g>\n<!-- S1 -->\n<g id=\"node3\" class=\"node\">\n<title>S1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"166.98\" cy=\"-103\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"166.98\" y=\"-98.33\" font-family=\"Times,serif\" font-size=\"14.00\">S1</text>\n</g>\n<!-- S0&#45;&gt;S1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>S0&#45;&gt;S1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.68,-103C102.41,-103 118.33,-103 132.32,-103\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"132.09,-105.98 140.59,-103 132.09,-100.03 132.09,-105.98\"/>\n<text text-anchor=\"middle\" x=\"115.98\" y=\"-106.95\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S2 -->\n<g id=\"node10\" class=\"node\">\n<title>S2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"268.23\" cy=\"-103\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"268.23\" y=\"-98.33\" font-family=\"Times,serif\" font-size=\"14.00\">S2</text>\n</g>\n<!-- S1&#45;&gt;S2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>S1&#45;&gt;S2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.75,-103C204.4,-103 220.15,-103 233.99,-103\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.64,-105.98 242.14,-103 233.64,-100.03 233.64,-105.98\"/>\n<text text-anchor=\"middle\" x=\"217.61\" y=\"-106.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S10 -->\n<g id=\"node4\" class=\"node\">\n<title>S10</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"783.81\" cy=\"-59\" rx=\"30.69\" ry=\"30.69\"/>\n<text text-anchor=\"middle\" x=\"783.81\" y=\"-54.33\" font-family=\"Times,serif\" font-size=\"14.00\">S10</text>\n</g>\n<!-- S6 -->\n<g id=\"node14\" class=\"node\">\n<title>S6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"891.38\" cy=\"-96\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"891.38\" y=\"-91.33\" font-family=\"Times,serif\" font-size=\"14.00\">S6</text>\n</g>\n<!-- S10&#45;&gt;S6 -->\n<g id=\"edge15\" class=\"edge\">\n<title>S10&#45;&gt;S6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M813.1,-68.92C827.23,-73.87 844.36,-79.87 858.91,-84.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"857.6,-87.66 866.6,-87.67 859.56,-82.05 857.6,-87.66\"/>\n<text text-anchor=\"middle\" x=\"840.75\" y=\"-83.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S11 -->\n<g id=\"node5\" class=\"node\">\n<title>S11</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"998.94\" cy=\"-158\" rx=\"30.69\" ry=\"30.69\"/>\n<text text-anchor=\"middle\" x=\"998.94\" y=\"-153.32\" font-family=\"Times,serif\" font-size=\"14.00\">S11</text>\n</g>\n<!-- S12 -->\n<g id=\"node6\" class=\"node\">\n<title>S12</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1112.82\" cy=\"-158\" rx=\"30.69\" ry=\"30.69\"/>\n<text text-anchor=\"middle\" x=\"1112.82\" y=\"-153.32\" font-family=\"Times,serif\" font-size=\"14.00\">S12</text>\n</g>\n<!-- S11&#45;&gt;S12 -->\n<g id=\"edge16\" class=\"edge\">\n<title>S11&#45;&gt;S12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1029.92,-158C1042.84,-158 1058.13,-158 1071.98,-158\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1071.74,-160.98 1080.24,-158 1071.74,-155.03 1071.74,-160.98\"/>\n<text text-anchor=\"middle\" x=\"1055.88\" y=\"-161.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S13 -->\n<g id=\"node7\" class=\"node\">\n<title>S13</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1227.45\" cy=\"-158\" rx=\"30.69\" ry=\"30.69\"/>\n<text text-anchor=\"middle\" x=\"1227.45\" y=\"-153.32\" font-family=\"Times,serif\" font-size=\"14.00\">S13</text>\n</g>\n<!-- S12&#45;&gt;S13 -->\n<g id=\"edge17\" class=\"edge\">\n<title>S12&#45;&gt;S13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1144,-158C1157.11,-158 1172.65,-158 1186.68,-158\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1186.56,-160.98 1195.06,-158 1186.56,-155.03 1186.56,-160.98\"/>\n<text text-anchor=\"middle\" x=\"1170.14\" y=\"-161.95\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S14 -->\n<g id=\"node8\" class=\"node\">\n<title>S14</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1341.33\" cy=\"-158\" rx=\"30.69\" ry=\"30.69\"/>\n<text text-anchor=\"middle\" x=\"1341.33\" y=\"-153.32\" font-family=\"Times,serif\" font-size=\"14.00\">S14</text>\n</g>\n<!-- S13&#45;&gt;S14 -->\n<g id=\"edge18\" class=\"edge\">\n<title>S13&#45;&gt;S14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1258.43,-158C1271.35,-158 1286.64,-158 1300.49,-158\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1300.25,-160.98 1308.75,-158 1300.25,-155.03 1300.25,-160.98\"/>\n<text text-anchor=\"middle\" x=\"1284.39\" y=\"-161.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S15 -->\n<g id=\"node9\" class=\"node\">\n<title>S15</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1460.71\" cy=\"-158\" rx=\"30.69\" ry=\"30.69\"/>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1460.71\" cy=\"-158\" rx=\"34.69\" ry=\"34.69\"/>\n<text text-anchor=\"middle\" x=\"1460.71\" y=\"-153.32\" font-family=\"Times,serif\" font-size=\"14.00\">S15</text>\n</g>\n<!-- S14&#45;&gt;S15 -->\n<g id=\"edge19\" class=\"edge\">\n<title>S14&#45;&gt;S15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1372.25,-158C1385.5,-158 1401.34,-158 1415.88,-158\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1415.68,-160.98 1424.18,-158 1415.68,-155.03 1415.68,-160.98\"/>\n<text text-anchor=\"middle\" x=\"1399.02\" y=\"-161.95\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S3 -->\n<g id=\"node11\" class=\"node\">\n<title>S3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"370.98\" cy=\"-103\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"370.98\" y=\"-98.33\" font-family=\"Times,serif\" font-size=\"14.00\">S3</text>\n</g>\n<!-- S2&#45;&gt;S3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>S2&#45;&gt;S3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M292.85,-103C305.77,-103 322,-103 336.23,-103\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"336.15,-105.98 344.65,-103 336.15,-100.03 336.15,-105.98\"/>\n<text text-anchor=\"middle\" x=\"319.61\" y=\"-106.95\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S4 -->\n<g id=\"node12\" class=\"node\">\n<title>S4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"472.24\" cy=\"-103\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"472.24\" y=\"-98.33\" font-family=\"Times,serif\" font-size=\"14.00\">S4</text>\n</g>\n<!-- S3&#45;&gt;S4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>S3&#45;&gt;S4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M395.76,-103C408.4,-103 424.15,-103 437.99,-103\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"437.64,-105.98 446.14,-103 437.64,-100.03 437.64,-105.98\"/>\n<text text-anchor=\"middle\" x=\"421.61\" y=\"-106.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S4&#45;&gt;S11 -->\n<g id=\"edge6\" class=\"edge\">\n<title>S4&#45;&gt;S11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M485.93,-123.44C502.58,-147.44 534.24,-184 572.49,-184 572.49,-184 572.49,-184 892.38,-184 915.41,-184 940.47,-178.09 960.39,-171.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"961.12,-174.8 968.29,-169.34 959.29,-169.14 961.12,-174.8\"/>\n<text text-anchor=\"middle\" x=\"726.12\" y=\"-187.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S5 -->\n<g id=\"node13\" class=\"node\">\n<title>S5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"573.49\" cy=\"-103\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"573.49\" y=\"-98.33\" font-family=\"Times,serif\" font-size=\"14.00\">S5</text>\n</g>\n<!-- S4&#45;&gt;S5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>S4&#45;&gt;S5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M497.01,-103C509.66,-103 525.41,-103 539.25,-103\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"538.9,-105.98 547.4,-103 538.9,-100.03 538.9,-105.98\"/>\n<text text-anchor=\"middle\" x=\"522.86\" y=\"-106.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S7 -->\n<g id=\"node15\" class=\"node\">\n<title>S7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"674.74\" cy=\"-131\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"674.74\" y=\"-126.33\" font-family=\"Times,serif\" font-size=\"14.00\">S7</text>\n</g>\n<!-- S5&#45;&gt;S7 -->\n<g id=\"edge9\" class=\"edge\">\n<title>S5&#45;&gt;S7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M597.01,-109.35C610.12,-113.05 626.86,-117.77 641.36,-121.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"640.52,-124.72 649.51,-124.16 642.14,-118.99 640.52,-124.72\"/>\n<text text-anchor=\"middle\" x=\"624.12\" y=\"-121.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S9 -->\n<g id=\"node17\" class=\"node\">\n<title>S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"674.74\" cy=\"-62\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"674.74\" y=\"-57.33\" font-family=\"Times,serif\" font-size=\"14.00\">S9</text>\n</g>\n<!-- S5&#45;&gt;S9 -->\n<g id=\"edge8\" class=\"edge\">\n<title>S5&#45;&gt;S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M596.52,-93.9C610.14,-88.27 627.83,-80.97 642.84,-74.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"643.66,-77.65 650.38,-71.65 641.39,-72.15 643.66,-77.65\"/>\n<text text-anchor=\"middle\" x=\"624.12\" y=\"-87.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S6&#45;&gt;S11 -->\n<g id=\"edge10\" class=\"edge\">\n<title>S6&#45;&gt;S11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M912.98,-108.1C927.39,-116.56 946.97,-128.07 963.71,-137.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"962.01,-140.35 970.85,-142.09 965.03,-135.22 962.01,-140.35\"/>\n<text text-anchor=\"middle\" x=\"942\" y=\"-131.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S6&#45;&gt;S4 -->\n<g id=\"edge11\" class=\"edge\">\n<title>S6&#45;&gt;S4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M879.23,-74.69C862.72,-46.41 828.9,0 784.81,0 572.49,0 572.49,0 572.49,0 532.03,0 502.87,-41.72 487.01,-72.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"484.53,-70.36 483.39,-79.3 489.85,-73.03 484.53,-70.36\"/>\n<text text-anchor=\"middle\" x=\"674.74\" y=\"-3.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S8 -->\n<g id=\"node16\" class=\"node\">\n<title>S8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"783.81\" cy=\"-132\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"783.81\" y=\"-127.33\" font-family=\"Times,serif\" font-size=\"14.00\">S8</text>\n</g>\n<!-- S7&#45;&gt;S8 -->\n<g id=\"edge12\" class=\"edge\">\n<title>S7&#45;&gt;S8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M699.5,-131.22C714.2,-131.36 733.28,-131.54 749.47,-131.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"749.07,-134.66 757.6,-131.76 749.13,-128.71 749.07,-134.66\"/>\n<text text-anchor=\"middle\" x=\"726.12\" y=\"-134.95\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S8&#45;&gt;S6 -->\n<g id=\"edge13\" class=\"edge\">\n<title>S8&#45;&gt;S6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M807.46,-124.28C822.35,-119.2 842.05,-112.48 858.51,-106.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"859.25,-109.76 866.33,-104.2 857.33,-104.13 859.25,-109.76\"/>\n<text text-anchor=\"middle\" x=\"840.75\" y=\"-118.95\" font-family=\"Times,serif\" font-size=\"14.00\"> ε </text>\n</g>\n<!-- S9&#45;&gt;S10 -->\n<g id=\"edge14\" class=\"edge\">\n<title>S9&#45;&gt;S10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M699.5,-61.33C712.32,-60.98 728.47,-60.52 743.13,-60.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"743.06,-63.09 751.47,-59.88 742.89,-57.14 743.06,-63.09\"/>\n<text text-anchor=\"middle\" x=\"726.12\" y=\"-63.95\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x721d8dc41110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 10.0.1 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"576pt\" height=\"190pt\"\n viewBox=\"0.00 0.00 576.00 189.59\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.321259 0.321259) rotate(0) translate(4 586.15)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-586.15 1788.95,-586.15 1788.95,4 -4,4\"/>\n<!-- Initial -->\n<g id=\"node1\" class=\"node\">\n<title>Initial</title>\n<ellipse fill=\"black\" stroke=\"black\" cx=\"1.8\" cy=\"-345.41\" rx=\"1.8\" ry=\"1.8\"/>\n</g>\n<!-- S0 -->\n<g id=\"node3\" class=\"node\">\n<title>S0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"64.98\" cy=\"-345.41\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"64.98\" y=\"-340.74\" font-family=\"Times,serif\" font-size=\"14.00\">S0</text>\n</g>\n<!-- Initial&#45;&gt;S0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>Initial&#45;&gt;S0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3.86,-345.41C7.28,-345.41 18.48,-345.41 30.31,-345.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.21,-348.39 38.71,-345.41 30.21,-342.44 30.21,-348.39\"/>\n</g>\n<g id=\"node2\" class=\"node\">\n<title></title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"412.83\" cy=\"-383.41\" rx=\"18\" ry=\"18\"/>\n</g>\n<!-- &#45;&gt; -->\n<g id=\"edge12\" class=\"edge\">\n<title>&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M399.98,-396.71C394.48,-407.81 398.77,-419.41 412.83,-419.41 422.73,-419.41 427.78,-413.68 428,-406.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"430.9,-405.76 426.04,-398.18 425.12,-407.14 430.9,-405.76\"/>\n<text text-anchor=\"middle\" x=\"412.83\" y=\"-423.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- &#45;&gt; -->\n<g id=\"edge13\" class=\"edge\">\n<title>&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M397.16,-392.7C373.31,-411.55 378.53,-437.41 412.83,-437.41 443.11,-437.41 450.74,-417.25 435.7,-399.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"437.81,-397.47 429.61,-393.75 433.7,-401.77 437.81,-397.47\"/>\n<text text-anchor=\"middle\" x=\"412.83\" y=\"-441.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S0&#45;&gt; -->\n<g id=\"edge3\" class=\"edge\">\n<title>S0&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.15,-349.51C95.07,-350.51 101.44,-351.54 107.35,-352.41 167.01,-361.22 181.99,-363.16 241.97,-369.41 292.17,-374.65 350.87,-379.12 384.47,-381.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"384.25,-384.49 392.94,-382.12 384.67,-378.56 384.25,-384.49\"/>\n<text text-anchor=\"middle\" x=\"183.29\" y=\"-372.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S1,S2 -->\n<g id=\"node4\" class=\"node\">\n<title>S1,S2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"183.29\" cy=\"-306.41\" rx=\"40.69\" ry=\"40.69\"/>\n<text text-anchor=\"middle\" x=\"183.29\" y=\"-301.74\" font-family=\"Times,serif\" font-size=\"14.00\">S1,S2</text>\n</g>\n<!-- S0&#45;&gt;S1,S2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>S0&#45;&gt;S1,S2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M88.4,-337.89C101.65,-333.45 118.93,-327.66 135.05,-322.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.82,-325.13 142.93,-319.61 133.92,-319.49 135.82,-325.13\"/>\n<text text-anchor=\"middle\" x=\"115.98\" y=\"-335.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S1,S2&#45;&gt; -->\n<g id=\"edge4\" class=\"edge\">\n<title>S1,S2&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.32,-327.68C235.63,-337.68 257.33,-349 277.97,-356.41 313.79,-369.27 357.31,-376.62 384.8,-380.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"384.19,-383.23 393,-381.36 384.94,-377.33 384.19,-383.23\"/>\n<text text-anchor=\"middle\" x=\"250.97\" y=\"-353.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S11,S12,S3,S4,S5,S7,S9 -->\n<g id=\"node8\" class=\"node\">\n<title>S11,S12,S3,S4,S5,S7,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"412.83\" cy=\"-212.41\" rx=\"134.86\" ry=\"134.86\"/>\n<text text-anchor=\"middle\" x=\"412.83\" y=\"-207.74\" font-family=\"Times,serif\" font-size=\"14.00\">S11,S12,S3,S4,S5,S7,S9</text>\n</g>\n<!-- S1,S2&#45;&gt;S11,S12,S3,S4,S5,S7,S9 -->\n<g id=\"edge5\" class=\"edge\">\n<title>S1,S2&#45;&gt;S11,S12,S3,S4,S5,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M221.35,-291.1C237.55,-284.41 257.63,-276.12 278.62,-267.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"279.55,-270.28 286.27,-264.29 277.28,-264.78 279.55,-270.28\"/>\n<text text-anchor=\"middle\" x=\"250.97\" y=\"-285.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S10,S11,S12,S15,S4,S5,S6,S7,S9 -->\n<g id=\"node5\" class=\"node\">\n<title>S10,S11,S12,S15,S4,S5,S6,S7,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1600.84\" cy=\"-236.41\" rx=\"180.1\" ry=\"180.1\"/>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1600.84\" cy=\"-236.41\" rx=\"184.1\" ry=\"184.1\"/>\n<text text-anchor=\"middle\" x=\"1600.84\" y=\"-231.74\" font-family=\"Times,serif\" font-size=\"14.00\">S10,S11,S12,S15,S4,S5,S6,S7,S9</text>\n</g>\n<!-- S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"node6\" class=\"node\">\n<title>S10,S11,S12,S4,S5,S6,S7,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"759.18\" cy=\"-389.41\" rx=\"157.48\" ry=\"157.48\"/>\n<text text-anchor=\"middle\" x=\"759.18\" y=\"-384.74\" font-family=\"Times,serif\" font-size=\"14.00\">S10,S11,S12,S4,S5,S6,S7,S9</text>\n</g>\n<!-- S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"edge15\" class=\"edge\">\n<title>S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1474.26,-370.49C1440.9,-397.81 1402.89,-422.69 1362.74,-437.41 1219.3,-490.03 1044.14,-467.28 919.72,-437.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"920.53,-435 911.57,-435.91 919.14,-440.79 920.53,-435\"/>\n<text text-anchor=\"middle\" x=\"1166.32\" y=\"-472.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"node7\" class=\"node\">\n<title>S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1166.32\" cy=\"-196.41\" rx=\"196.41\" ry=\"196.41\"/>\n<text text-anchor=\"middle\" x=\"1166.32\" y=\"-191.74\" font-family=\"Times,serif\" font-size=\"14.00\">S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</text>\n</g>\n<!-- S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge14\" class=\"edge\">\n<title>S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1420.58,-197.75C1413.22,-196.76 1405.92,-195.89 1398.74,-195.16 1390.31,-194.31 1381.71,-193.6 1373.01,-193.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1373.33,-190.07 1364.67,-192.52 1372.97,-196.01 1373.33,-190.07\"/>\n<text text-anchor=\"middle\" x=\"1389.74\" y=\"-199.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M733.02,-545.14C738.77,-557.35 747.49,-564.9 759.18,-564.9 767.94,-564.9 775.04,-560.65 780.46,-553.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"782.8,-555.28 784.56,-546.45 777.68,-552.25 782.8,-555.28\"/>\n<text text-anchor=\"middle\" x=\"759.18\" y=\"-568.85\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge8\" class=\"edge\">\n<title>S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M901.88,-321.91C926.99,-309.95 953.48,-297.33 979.59,-284.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"980.67,-287.67 987.07,-281.33 978.11,-282.3 980.67,-287.67\"/>\n<text text-anchor=\"middle\" x=\"943.28\" y=\"-309.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S10,S11,S12,S15,S4,S5,S6,S7,S9 -->\n<g id=\"edge11\" class=\"edge\">\n<title>S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S10,S11,S12,S15,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1362.39,-214.45C1377.37,-215.84 1392.48,-217.24 1407.44,-218.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1407,-221.57 1415.74,-219.39 1407.55,-215.64 1407,-221.57\"/>\n<text text-anchor=\"middle\" x=\"1389.74\" y=\"-222.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge10\" class=\"edge\">\n<title>S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1136.83,-390.99C1143.75,-403.36 1153.58,-410.83 1166.32,-410.83 1176.08,-410.83 1184.13,-406.45 1190.47,-398.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1192.64,-400.95 1194.96,-392.25 1187.72,-397.6 1192.64,-400.95\"/>\n<text text-anchor=\"middle\" x=\"1166.32\" y=\"-414.78\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S11,S12,S3,S4,S5,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"edge7\" class=\"edge\">\n<title>S11,S12,S3,S4,S5,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M533.3,-273.82C558,-286.52 584.29,-300.03 609.87,-313.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"608.25,-315.69 617.17,-316.93 610.97,-310.4 608.25,-315.69\"/>\n<text text-anchor=\"middle\" x=\"574.69\" y=\"-300.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S11,S12,S3,S4,S5,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge6\" class=\"edge\">\n<title>S11,S12,S3,S4,S5,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548,-207.69C566.05,-207.13 584.32,-206.6 601.69,-206.16 720.29,-203.17 852.94,-200.82 959.75,-199.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"959.71,-202.16 968.16,-199.05 959.62,-196.21 959.71,-202.16\"/>\n<text text-anchor=\"middle\" x=\"759.18\" y=\"-210.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x721d8dc42b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 10.0.1 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"576pt\" height=\"257pt\"\n viewBox=\"0.00 0.00 576.00 257.15\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.392043 0.392043) rotate(0) translate(4 651.91)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-651.91 1465.23,-651.91 1465.23,4 -4,4\"/>\n<!-- Initial -->\n<g id=\"node1\" class=\"node\">\n<title>Initial</title>\n<ellipse fill=\"black\" stroke=\"black\" cx=\"1.8\" cy=\"-521.41\" rx=\"1.8\" ry=\"1.8\"/>\n</g>\n<!-- S0 -->\n<g id=\"node3\" class=\"node\">\n<title>S0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"64.98\" cy=\"-521.41\" rx=\"24.38\" ry=\"24.38\"/>\n<text text-anchor=\"middle\" x=\"64.98\" y=\"-516.74\" font-family=\"Times,serif\" font-size=\"14.00\">S0</text>\n</g>\n<!-- Initial&#45;&gt;S0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>Initial&#45;&gt;S0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3.86,-521.41C7.28,-521.41 18.48,-521.41 30.31,-521.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"30.21,-524.39 38.71,-521.41 30.21,-518.44 30.21,-524.39\"/>\n</g>\n<g id=\"node2\" class=\"node\">\n<title></title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"435.46\" cy=\"-559.41\" rx=\"18\" ry=\"18\"/>\n</g>\n<!-- &#45;&gt; -->\n<g id=\"edge10\" class=\"edge\">\n<title>&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M421.74,-571.21C414.16,-582.74 418.74,-595.41 435.46,-595.41 447.74,-595.41 453.46,-588.58 452.64,-580.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"455.5,-579.53 449.71,-572.63 449.93,-581.63 455.5,-579.53\"/>\n<text text-anchor=\"middle\" x=\"435.46\" y=\"-599.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- &#45;&gt; -->\n<g id=\"edge11\" class=\"edge\">\n<title>&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M419.16,-567.67C390.29,-586.59 395.72,-613.41 435.46,-613.41 471.16,-613.41 479.17,-591.76 459.49,-573.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"461.5,-571.43 452.95,-568.59 457.86,-576.14 461.5,-571.43\"/>\n<text text-anchor=\"middle\" x=\"435.46\" y=\"-617.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S0&#45;&gt; -->\n<g id=\"edge3\" class=\"edge\">\n<title>S0&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.15,-525.51C95.07,-526.51 101.44,-527.54 107.35,-528.41 167.01,-537.22 181.96,-539.45 241.97,-545.41 300.94,-551.28 370.31,-555.72 407.56,-557.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"407.01,-560.86 415.67,-558.38 407.35,-554.92 407.01,-560.86\"/>\n<text text-anchor=\"middle\" x=\"183.29\" y=\"-548.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S1,S2 -->\n<g id=\"node4\" class=\"node\">\n<title>S1,S2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"183.29\" cy=\"-482.41\" rx=\"40.69\" ry=\"40.69\"/>\n<text text-anchor=\"middle\" x=\"183.29\" y=\"-477.74\" font-family=\"Times,serif\" font-size=\"14.00\">S1,S2</text>\n</g>\n<!-- S0&#45;&gt;S1,S2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>S0&#45;&gt;S1,S2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M88.4,-513.89C101.65,-509.45 118.93,-503.66 135.05,-498.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.82,-501.13 142.93,-495.61 133.92,-495.49 135.82,-501.13\"/>\n<text text-anchor=\"middle\" x=\"115.98\" y=\"-511.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S1,S2&#45;&gt; -->\n<g id=\"edge4\" class=\"edge\">\n<title>S1,S2&#45;&gt;</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.23,-503.93C235.52,-513.99 257.22,-525.29 277.97,-532.41 321.78,-547.45 375.49,-554.38 407.23,-557.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"406.87,-560.32 415.6,-558.1 407.39,-554.39 406.87,-560.32\"/>\n<text text-anchor=\"middle\" x=\"250.97\" y=\"-529.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"node6\" class=\"node\">\n<title>S10,S11,S12,S4,S5,S6,S7,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"435.46\" cy=\"-330.41\" rx=\"157.48\" ry=\"157.48\"/>\n<text text-anchor=\"middle\" x=\"435.46\" y=\"-325.74\" font-family=\"Times,serif\" font-size=\"14.00\">S10,S11,S12,S4,S5,S6,S7,S9</text>\n</g>\n<!-- S1,S2&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"edge5\" class=\"edge\">\n<title>S1,S2&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.55,-461.6C238.26,-449.62 264.49,-433.69 291.86,-417.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293.37,-419.62 299.09,-412.66 290.29,-414.53 293.37,-419.62\"/>\n<text text-anchor=\"middle\" x=\"250.97\" y=\"-450.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S10,S11,S12,S15,S4,S5,S6,S7,S9 -->\n<g id=\"node5\" class=\"node\">\n<title>S10,S11,S12,S15,S4,S5,S6,S7,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1277.12\" cy=\"-236.41\" rx=\"180.1\" ry=\"180.1\"/>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1277.12\" cy=\"-236.41\" rx=\"184.1\" ry=\"184.1\"/>\n<text text-anchor=\"middle\" x=\"1277.12\" y=\"-231.74\" font-family=\"Times,serif\" font-size=\"14.00\">S10,S11,S12,S15,S4,S5,S6,S7,S9</text>\n</g>\n<!-- S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"edge13\" class=\"edge\">\n<title>S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1150.54,-370.49C1117.18,-397.81 1079.17,-422.69 1039.02,-437.41 875.11,-497.54 815.95,-478.22 646.19,-437.41 624.19,-432.13 601.9,-424.13 580.48,-414.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"581.71,-412.12 572.74,-411.39 579.29,-417.56 581.71,-412.12\"/>\n<text text-anchor=\"middle\" x=\"842.6\" y=\"-480.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"node7\" class=\"node\">\n<title>S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"842.6\" cy=\"-196.41\" rx=\"196.41\" ry=\"196.41\"/>\n<text text-anchor=\"middle\" x=\"842.6\" y=\"-191.74\" font-family=\"Times,serif\" font-size=\"14.00\">S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</text>\n</g>\n<!-- S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge12\" class=\"edge\">\n<title>S10,S11,S12,S15,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1096.86,-197.75C1089.5,-196.76 1082.2,-195.89 1075.02,-195.16 1066.6,-194.31 1057.99,-193.6 1049.29,-193.03\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1049.61,-190.07 1040.95,-192.52 1049.26,-196.01 1049.61,-190.07\"/>\n<text text-anchor=\"middle\" x=\"1066.02\" y=\"-199.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9 -->\n<g id=\"edge7\" class=\"edge\">\n<title>S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S10,S11,S12,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M409.3,-486.14C415.05,-498.35 423.77,-505.9 435.46,-505.9 444.22,-505.9 451.32,-501.65 456.74,-494.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"459.08,-496.28 460.84,-487.45 453.96,-493.25 459.08,-496.28\"/>\n<text text-anchor=\"middle\" x=\"435.46\" y=\"-509.85\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge6\" class=\"edge\">\n<title>S10,S11,S12,S4,S5,S6,S7,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M585.31,-281.18C605.17,-274.61 625.79,-267.79 646.3,-261.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"647.14,-263.87 654.28,-258.37 645.27,-258.22 647.14,-263.87\"/>\n<text text-anchor=\"middle\" x=\"619.56\" y=\"-276.36\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n<!-- S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S10,S11,S12,S15,S4,S5,S6,S7,S9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S10,S11,S12,S15,S4,S5,S6,S7,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1038.67,-214.45C1053.65,-215.84 1068.76,-217.24 1083.72,-218.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1083.29,-221.57 1092.02,-219.39 1083.83,-215.64 1083.29,-221.57\"/>\n<text text-anchor=\"middle\" x=\"1066.02\" y=\"-222.36\" font-family=\"Times,serif\" font-size=\"14.00\"> b </text>\n</g>\n<!-- S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9 -->\n<g id=\"edge8\" class=\"edge\">\n<title>S11,S12,S13,S14,S4,S5,S6,S7,S8,S9&#45;&gt;S11,S12,S13,S14,S4,S5,S6,S7,S8,S9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M813.11,-390.99C820.03,-403.36 829.86,-410.83 842.6,-410.83 852.36,-410.83 860.41,-406.45 866.75,-398.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"868.92,-400.95 871.24,-392.25 864,-397.6 868.92,-400.95\"/>\n<text text-anchor=\"middle\" x=\"842.6\" y=\"-414.78\" font-family=\"Times,serif\" font-size=\"14.00\"> a </text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x721d8dfd9310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nfa = convert(\"ab(a|b)*ab\")\n",
    "visualize(fa=nfa, type=AutomatonType.NFA)\n",
    "\n",
    "dfa = subset_construction(nfa=nfa)\n",
    "visualize(fa=dfa, type=AutomatonType.DFA, allow_partial=True)\n",
    "\n",
    "minimized_dfa = minimize_dfa(dfa)\n",
    "visualize(fa=minimized_dfa, type=AutomatonType.DFA, allow_partial=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88693592a8af6d3914c90125582dc8ed11ea8198fbca1042d2179d6441d517fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
